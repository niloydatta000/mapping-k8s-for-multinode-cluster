# GitOps Observability: FluxCD, Prometheus & ELK Stack


This file manages a multi-node Kubernetes cluster using GitOps principles. By utilizing FluxCD, the cluster state is automatically synchronized with the manifests defined in a private repository.


## Architecture Overview

- **GitOps Controller:** [FluxCD](https://fluxcd.io/)

- **Monitoring:** [Prometheus](https://prometheus.io/) & [Grafana](https://grafana.com/) (via kube-prometheus-stack)

- **Logging:** [ELK Stack](https://www.elastic.co/elastic-stack) (Elasticsearch, Fluent-bit, Kibana)

- **Network:** MetalLB & NGINX Ingress (Pre-requisites)

## FluxCD Bootstrapping

Create an `.env` file in a safe location in the Master Node for fetching environment variables in the [flux-bootstrap.sh](./flux-bootstrap.sh) script.

The `.env` file should contain the following variables and be assigned their respective values.

- **GITHUB_TOKEN**
- **GITHUB_USER**
- **REPO_NAME**
- **BRANCH_NAME**

Run the script from the Master Node to link the cluster to our **private GitHub repository**.

```bash
chmod +x flux-bootstrap.sh
./flux-bootstrap.sh --config .env
```


## Repository Structure

We use a *Modular* structure to separate the **Cluster Entrypoint** from the Application Definitions in our private repository.

```
.
├── clusters/
│   └── my-cluster/
│       ├── flux-system/       # Autogenerated by Flux
│       ├── infrastructure.yaml # Pointers to Helm Repos
│       └── monitoring.yaml     # Pointers to Prometheus/ELK
└── infrastructure/
    ├── sources/               # External Chart Repositories
    ├── prometheus/            # Prometheus & Grafana Config
    └── elk-stack/             # Elasticsearch & Kibana Config
```

### Contents of `clusters/my-cluster/infrastructure.yaml`

```yaml
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: infra-sync
  namespace: flux-system
spec:
  interval: 10m
  path: ./infrastructure
  prune: true
  sourceRef:
    kind: GitRepository
    name: flux-system
  wait: true
```


## Defining External Sources

We must tell Flux where to find official `helm` repositories. Push this to `infrastructure/sources/helm-repos.yaml`:

```yaml
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: prometheus-community
  namespace: flux-system
spec:
  interval: 1h
  url: https://prometheus-community.github.io/helm-charts
---
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: elastic
  namespace: flux-system
spec:
  interval: 1h
  url: https://helm.elastic.co
```


## The Monitoring Stack (Standard Helm)

Push this to `infrastructure/prometheus/release.yaml`. This uses the official kube-prometheus-stack.
```yaml
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kube-stack
  namespace: monitoring
spec:
  chart:
    spec:
      chart: kube-prometheus-stack
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
  interval: 1h
  values:
    grafana:
      adminPassword: "admin" # Change in production
    prometheus:
      prometheusSpec:
        storageSpec:
          emptyDir: { medium: Memory } # Saves Disk I/O on small nodes
```

## The ELK Stack (Official Elastic Charts)

We utilize the official Elastic Helm Charts. Below are two configuration strategies: one for restricted hardware (4GB RAM) and one for production-grade hardware (8GB+ RAM).


### Option A: Survival Mode (4GB RAM Nodes)

This configuration minimizes the footprint by running a single-node instance and forcing the **Java Virtual Machine (JVM)** to stay within a strict 1GB limit to prevent the Node from crashing.

```yaml
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: elasticsearch
  namespace: logging
spec:
  chart:
    spec:
      chart: elasticsearch
      version: "8.x.x" # Change It Official Elastic Version
      sourceRef:
        kind: HelmRepository
        name: elastic
        namespace: flux-system
  interval: 1h
  values:
    replicas: 1            # Only 1 pod to save RAM
    minimumMasterNodes: 1
    persistence:
      enabled: false       # Uses emptyDir for speed on slow VPS
    resources:
      requests:
        cpu: "500m"
        memory: "1Gi"
      limits:
        cpu: "1000m"
        memory: "2Gi"
    esJavaOpts: "-Xmx1g -Xms1g" # Forces Java to 1GB Heap
```

### Option B: Production Mode (8GB+ RAM Nodes)

With sufficient RAM, we can enable High Availability (HA). This creates a multi-node Elasticsearch cluster where data is replicated. If one worker node fails, your logs remain safe and searchable.

```yaml
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: elasticsearch
  namespace: logging
spec:
  chart:
    spec:
      chart: elasticsearch
      version: "8.x.x" # Change It Official Elastic Ver    sion (Same As Previously mentiined)
      sourceRef:
        kind: HelmRepository
        name: elastic
        namespace: flux-system
  interval: 1h
  values:
    replicas: 3            # Spreads pods minimum across 3 nodes
    minimumMasterNodes: 2  # Prevents "Split Brain" scenario
    persistence:
      enabled: true        # Saves logs to disk permanently
      size: 30Gi
    resources:
      requests:
        cpu: "1000m"
        memory: "4Gi"
      limits:
        cpu: "2000m"
        memory: "6Gi"
    esJavaOpts: "-Xmx4g -Xms4g" # Provides 4GB Heap for heavy searching
```


## CI/CD Pipeline (GitHub Actions)

Create `.github/workflows/flux-diff.yml`.
This automatically validates your **YAML** files whenever you create a Pull Request.

```yaml
name: Flux Validation
on: [pull_request]
jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Flux CLI
        run: curl -fsSL https://fluxcd.io/install.sh | sudo bash
      - name: Validate Manifests
        run: |
          flux check --pre
          # Add kustomize build tests here
```


## Verification Commands

Once these files are pushed, use these commands on the Master Node to watch Flux build your infrastructure:

**Check Sync Status:**

```bash
flux get kustomizations
```
**Check Helm Releases:**

```bash
flux get helmreleases -A
```
**View Dashboards:**

```bash
kubectl port-forward svc/kube-stack-grafana -n monitoring 3000:80
```

## Accessing the Dashboards

Since the tools are internal to the cluster, use the following methods to access the Web UIs.

### Grafana (Metrics & Cluster Health)

Grafana is used for real-time visualization of CPU, RAM, and Network health.

**Access Command:**

```bash
kubectl port-forward svc/kube-stack-grafana -n monitoring 3000:80
```

Open a Browser and go to the URL: `http://localhost:3000`
**Default Credentials:** `admin / prom-operator` (or the password set in your HelmRelease).


### Kibana (Log Searching)

Kibana is the interface for searching through logs collected from your Master and Worker nodes.


**Access Command:**

```bash
kubectl port-forward svc/kibana-kibana -n logging 5601:5601
```

Go to the URL: `http://localhost:5601`




## How to use Grafana


### Pre-Configured Dashboards

The kube-prometheus-stack automatically installs official dashboards. Once logged in, go to **Dashboards -> Browse** and look for:

1. **Kubernetes / Compute Resources / Cluster:** Provides a *Bird's Eye View* of our nodes.

2. **Kubernetes / Compute Resources / Pod:** Use this to see exactly how much RAM your Elasticsearch pod is consuming.


### Creating an Alert

Go to **Alerting -> Alert Rules**. Set a threshold (e.g., Node RAM > 90%).

Grafana will highlight the graph in red when our 4GB nodes are under heavy load.

## How to use Kibana (ELK)

### Create a Data View

The first time we log in, we must tell Kibana which data to look at:

Go to **Stack Management -> Data Views**.

Click Create data view. Name it "Logs" and set the Index Pattern to filebeat-* or fluent-bit-* (depending on collector).

### The "Discover" Tab

This is the main troubleshooting tool.

- **Filtering:** Use the search bar to type kubernetes.namespace : "default".

- **Time Range:** Use the clock icon in the top right to look at logs from the "Last 15 minutes" or "Last 24 hours."

- **Live Tail:** Click the Stream button to watch logs scroll in real-time as you interact with your app.


## Verification: "Is it working?"

To ensure your Prometheus is successfully "monitoring" your ELK, run this query in the Prometheus UI or Grafana:

**Query:** `elasticsearch_jvm_memory_used_bytes`

- If you see a line: **Prometheus is successfully talking to ELK.**

- If you see **No Data**: Your `ServiceMonitor` (the bridge) is incorrectly configured or the ELK exporter is down.

